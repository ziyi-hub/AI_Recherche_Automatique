{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Neural Networks #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "Define the neural network that has some learnable parameters (or weights)\n",
    "\n",
    "Iterate over a dataset of inputs\n",
    "\n",
    "Process input through the network\n",
    "\n",
    "Compute the loss (how far is the output from being correct)\n",
    "\n",
    "Propagate gradients back into the network’s parameters\n",
    "\n",
    "Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "神经网络的典型训练过程如下：\n",
    "\n",
    "定义具有某些可学习参数（或权重）的神经网络\n",
    "\n",
    "对输入数据集进行迭代\n",
    "\n",
    "通过网络处理输入\n",
    "\n",
    "计算损失（输出离正确还有多远）\n",
    "\n",
    "将梯度传回网络参数中\n",
    "\n",
    "更新网络权重，通常使用简单的更新规则：权重 = 权重 - 学习率 * 梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrumentation et évaluation \"en continu\" du système ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: torchvision in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (0.17.0)\n",
      "Requirement already satisfied: filelock in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: numpy in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: requests in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from requests->torchvision) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/wangziyihuifei/miniconda3/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs, labels = data[0].to(device), data[1].to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 CNN 网络的训练部分，列出不同层和子层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La couche de convolution : ###\n",
    "La couche de convolution applique un ensemble de filtres convolutifs aux images en entrée, chacun d'entre eux activant certaines caractéristiques des images.\n",
    "- `self.conv1` Cette couche de convolution prend en entrée des images avec 3 canaux (RGB) et produit 6 canaux en sortie à l'aide d'un noyau de taille 5x5.\n",
    "- `self.conv2` Une deuxième couche de convolution qui prend les 6 canaux de sortie de la couche précédente et produit 16 canaux de sortie à l'aide d'un noyau de taille 5x5.\n",
    "\n",
    "### Les couches entièrement connectées : ###\n",
    "Chaque couche entièrement connectée effectue une transformation linéaire suivie d'une activation ReLU, qui introduit de la non-linéarité dans le réseau.  Du coup, dans chacune des couches entièrement connectées (`self.fc1`, `self.fc2` et `self.fc3`), il y a une sous-couche linéaire suivie d'une sous-couche non linéaire. Ces couches sont responsables de la combinaison des caractéristiques extraites par les couches de convolution précédentes pour effectuer la tâche de classification finale.\n",
    "\n",
    "`self.fc1` (Première couche entièrement connectée)\n",
    "- Sous-couche linéaire : C'est la première étape de la couche. Elle effectue une transformation linéaire des caractéristiques d'entrée.\n",
    "- Sous-couche non linéaire : Après la transformation linéaire, une activation ReLU est appliquée. Cela introduit de la non-linéarité dans la sortie de la couche.\n",
    "\n",
    "`self.fc2` (Deuxième couche entièrement connectée)\n",
    "- Sous-couche linéaire : Comme pour la première couche, cette couche effectue une transformation linéaire des caractéristiques.\n",
    "- Sous-couche non linéaire : Suite à la transformation linéaire, une activation ReLU est appliquée.\n",
    "\n",
    "`self.fc3` (Couche de sortie)\n",
    "- Sous-couche linéaire : Il s'agit de la dernière transformation linéaire qui produit la sortie finale du réseau.\n",
    "\n",
    "### La couche de pooling : ###\n",
    "L'opération de pooling consiste à réduire la taille des images, tout en préservant leurs caractéristiques importantes. Cette couche en effectuant une opération de max pooling avec une fenêtre de taille 2x2 et un pas de 2.\n",
    "- `self.pool` qui est utilisée après chaque couche de convolution\n",
    "\n",
    "### La couche de correction ReLU ###\n",
    "La couche de correction ReLU favorise un apprentissage plus rapide et plus efficace en remplaçant les valeurs négatives par des zéros et en conservant les valeurs positives.\n",
    "- Fonctions d'activation ReLU `F.relu` qui introduit de la non-linéarité dans le réseau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在计算过程中给出不同数据张量 Xn 和权重 Wn 的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose( # 创建了一个转换组合，将一系列的数据预处理操作组合在一起。这里使用了两个预处理操作\n",
    "    [transforms.ToTensor(), # 将图像转换为 PyTorch 张量，并将像素值缩放到 [0, 1] 的范围\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 对图像进行标准化处理，减去均值（0.5）并除以标准差（0.5）\n",
    "\n",
    "batch_size = 4 #指定了数据加载器每次加载的批次大小，这里设置为 4。\n",
    "\n",
    "# 创建了 CIFAR-10 数据集的训练集对象。root 参数指定了数据集存储的根目录，train=True 表示加载训练集，\n",
    "# download=True 表示如果数据集不存在则自动下载，transform=transform 表示应用之前定义的数据预处理操作。\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# 创建了一个训练集数据加载器。trainloader 负责从训练集中加载数据，shuffle=True 表示每个 epoch 都会对数据进行洗牌，\n",
    "# num_workers=2 表示使用两个子进程来加载数据以加快速度。\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "# 这里分别创建了 CIFAR-10 数据集的测试集对象和测试集数据加载器。\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in net.parameters(): \n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Layer 1 (conv1):\n",
    "- Taille de l'entrée: X1 = 3×32×32 = 3072\n",
    "- Poids W1:\n",
    "    - [6, 3, 5, 5]: Une première couche de convolution prend en entrée des images avec 3 canaux (RGB) et produit 6 canaux en sortie à l'aide d'un noyau de taille 5x5. Poids de convolution: 6×3×5×5=450\n",
    "    - Bias: 6\n",
    "\n",
    "Convolutional Layer 2 (conv2):\n",
    "- Taille de l'entrée: X2 = 6×14×14 = 1176\n",
    "- Poids W2:\n",
    "    - [16, 6, 5, 5]: Une deuxième couche de convolution qui prend les 6 canaux d'entrée(6 canaux en entrée provenant de la couche précédente) et produit 16 canaux de sortie à l'aide d'un noyau de taille 5x5. Poids de convolution: 16×6×5×5=2400\n",
    "    - Bias: 16\n",
    "\n",
    "Fully Connected Layer 1 (fc1):\n",
    "- Taille de l'entrée: X3 = 1×400 = 400\n",
    "- Poids W3:\n",
    "    - [120, 400]: Il y a 120 neurones dans la couche entièrement connectée, chacun connecté à une entrée de taille 400. Poids de convolution: 120×400 = 48000\n",
    "    - Bias: 120\n",
    "\n",
    "Fully Connected Layer 2 (fc2):\n",
    "- Taille de l'entrée: X4 = 1×120 = 120\n",
    "- Poids W4:\n",
    "    - [84, 120]: 84 neurones dans la deuxième couche entièrement connectée, chacun connecté aux 120 neurones de la couche précédente. Poids de convolution: 84×120=10080\n",
    "    - Bias: 84\n",
    "  \n",
    "Fully Connected Layer 3 (fc3):\n",
    "- Taille de l'entrée: X5 = 1×84 = 84\n",
    "- Poids W5:\n",
    "    - [10, 84]: 10 neurones dans la dernière couche entièrement connectée, chacun connecté aux 84 neurones de la couche précédente. Poids de convolution: 10×84=840\n",
    "    - Bias: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改程序，在每个历元之后和第一个历元之前进行评估（创建一个专门函数）。删除其他中间显示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这行代码定义了损失函数，即交叉熵损失函数。交叉熵损失函数通常用于多类别分类问题\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#这行代码定义了优化器，即随机梯度下降（SGD）优化器。SGD是一种常用的优化算法，用于更新神经网络的权重以最小化损失函数。\n",
    "#lr=0.001指定了学习率，即每次更新时的步长。momentum=0.9是SGD的一个超参数，用于加速SGD在相关方向上前进，并减小波动。\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 2.306\n",
      "Accuracy of the network on the 10000 test images: 6 %\n",
      "[1,  2000] loss: 2.219\n",
      "[1,  4000] loss: 1.863\n",
      "[1,  6000] loss: 1.671\n",
      "[1,  8000] loss: 1.577\n",
      "[1, 10000] loss: 1.527\n",
      "[1, 12000] loss: 1.473\n",
      "Epoch 1 Evaluation:\n",
      "Evaluation Loss: 1.449\n",
      "Accuracy of the network on the 10000 test images: 47 %\n",
      "[2,  2000] loss: 1.405\n",
      "[2,  4000] loss: 1.374\n",
      "[2,  6000] loss: 1.334\n",
      "[2,  8000] loss: 1.330\n",
      "[2, 10000] loss: 1.313\n",
      "[2, 12000] loss: 1.287\n",
      "Epoch 2 Evaluation:\n",
      "Evaluation Loss: 1.259\n",
      "Accuracy of the network on the 10000 test images: 54 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(net, dataloader, criterion):\n",
    "    eval_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            eval_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    eval_loss /= len(dataloader)\n",
    "    print(f'Evaluation Loss: {eval_loss:.3f}')\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
    "\n",
    "# Évaluation avant la première époque\n",
    "evaluate_model(net, testloader, criterion)\n",
    "\n",
    "def train(epoch_num):\n",
    "    # Boucle pour itérer sur plusieurs époques de l'ensemble de données\n",
    "    for epoch in range(epoch_num):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "            if i % 2000 == 1999:\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "    \n",
    "        # Évaluation après chaque époque\n",
    "        print(f'Epoch {epoch + 1} Evaluation:')\n",
    "        evaluate_model(net, testloader, criterion)\n",
    "\n",
    "epoch_num = 2\n",
    "train(epoch_num)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改函数以计算每个阶段执行的浮点运算次数，分别计算加法、乘法、最大值和总值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def count_operations(self, x):\n",
    "        conv1_out = self.conv1(x)\n",
    "        conv1_out_pooled = self.pool(F.relu(conv1_out))  # Apply max pooling after the first convolution\n",
    "        conv2_out = self.conv2(conv1_out_pooled)\n",
    "        \n",
    "        # Count operations for convolutional layer 1\n",
    "        conv1_ops = self.count_conv_operations(x, conv1_out, self.conv1)\n",
    "        \n",
    "        # Count operations for convolutional layer 2\n",
    "        conv2_ops = self.count_conv_operations(conv1_out_pooled, conv2_out, self.conv2)\n",
    "        \n",
    "        return conv1_ops, conv2_ops\n",
    "\n",
    "    \n",
    "    def count_conv_operations(self, input, output, conv_layer):\n",
    "        # batch_size = input.size(0)\n",
    "        out_channels, in_channels = output.size(1), conv_layer.in_channels\n",
    "        output_height, output_width = output.size(2), output.size(3)\n",
    "        filter_size = conv_layer.kernel_size[0]\n",
    "        stride = conv_layer.stride[0]\n",
    "        padding = conv_layer.padding[0]\n",
    "        \n",
    "        # Compute number of operations for convolution\n",
    "        print(str(output_height) + \" * \" + str(output_width) + \" * \" + str(in_channels) + \" * \" + str(filter_size**2) + \" * \" + str(out_channels))\n",
    "        num_mults = output_height * output_width * in_channels * filter_size ** 2 * out_channels\n",
    "        num_adds = output_height * output_width * in_channels * filter_size ** 2 * out_channels\n",
    "        num_maxs = output_height * output_width * out_channels\n",
    "        # 14 * 14 * 6 * 3?\n",
    "        # 5 * 5 * 16 * 3?\n",
    "        print(str(output_height) + \" * \" + str(output_width) + \" * \" + str(in_channels))\n",
    "        total_ops = num_mults + num_adds + num_maxs\n",
    "        return num_mults, num_adds, num_maxs, total_ops\n",
    "\n",
    "\n",
    "    def count_fc_operations(self, input, fc_layer):\n",
    "        # Get the number of input features for the fully connected layer\n",
    "        in_features = fc_layer.in_features\n",
    "        \n",
    "        # Get the number of output features for the fully connected layer\n",
    "        out_features = fc_layer.out_features\n",
    "                \n",
    "        # Compute number of operations for fully connected layer\n",
    "        print(str(out_features) + \" * \" + str(in_features))\n",
    "        num_mults = out_features * in_features\n",
    "        num_adds = out_features * in_features\n",
    "        num_maxs = 0\n",
    "                \n",
    "        total_ops = num_mults + num_adds\n",
    "        return num_mults, num_adds, num_maxs, total_ops\n",
    "\n",
    "    def count_total_operations(self, x):\n",
    "        conv1_ops, conv2_ops = self.count_operations(x)\n",
    "        fc1_ops = self.count_fc_operations(x, self.fc1)\n",
    "        fc2_ops = self.count_fc_operations(x, self.fc2)\n",
    "        fc3_ops = self.count_fc_operations(x, self.fc3)\n",
    "\n",
    "        total_ops = sum(op[3] for op in [conv1_ops, conv2_ops, fc1_ops, fc2_ops, fc3_ops])\n",
    "        return total_ops\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model weights\n",
    "PATH = './cifar_net.pth'\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [23]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Let's assume you have an iterator `dataiter` that iterates over your test data\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m dataiter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(\u001B[43mtestloader\u001B[49m) \n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Get the next batch of data\u001B[39;00m\n\u001B[1;32m      5\u001B[0m images, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(dataiter)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'testloader' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's assume you have an iterator `dataiter` that iterates over your test data\n",
    "dataiter = iter(testloader) \n",
    "\n",
    "# Get the next batch of data\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "# Compute operation counts for convolutional layer 1 and convolutional layer 2\n",
    "conv1_ops, conv2_ops = net.count_operations(images)\n",
    "\n",
    "# Compute operation counts for fully connected layer 1, layer 2, layer 3\n",
    "fc1_ops = net.count_fc_operations(images, net.fc1)\n",
    "fc2_ops = net.count_fc_operations(images, net.fc2)\n",
    "fc3_ops = net.count_fc_operations(images, net.fc3)\n",
    "\n",
    "total_ops = net.count_total_operations(images)\n",
    "\n",
    "# Print operation counts for convolutional layer 1\n",
    "print(\"Operations for convolutional layer 1:\")\n",
    "print(\"Multiplications :\", conv1_ops[0])\n",
    "print(\"Additions :\", conv1_ops[1])\n",
    "print(\"Maximums :\", conv1_ops[2])\n",
    "print(\"Total :\", conv1_ops[3])\n",
    "print()\n",
    "\n",
    "# Print operation counts for convolutional layer 2\n",
    "print(\"Operations for convolutional layer 2:\")\n",
    "print(\"Multiplications :\", conv2_ops[0])\n",
    "print(\"Additions :\", conv2_ops[1])\n",
    "print(\"Maximums :\", conv2_ops[2])\n",
    "print(\"Total :\", conv2_ops[3])\n",
    "print()\n",
    "\n",
    "# Print operation counts for fully connected layer 1\n",
    "print(\"Operations for fully connected layer 1:\")\n",
    "print(\"Multiplications :\", fc1_ops[0])\n",
    "print(\"Additions :\", fc1_ops[1])\n",
    "print(\"Maximums :\", fc1_ops[2])\n",
    "print(\"Total :\", fc1_ops[3])\n",
    "print()\n",
    "\n",
    "# Print operation counts for fully connected layer 2\n",
    "print(\"Operations for fully connected layer 2:\")\n",
    "print(\"Multiplications :\", fc2_ops[0])\n",
    "print(\"Additions :\", fc2_ops[1])\n",
    "print(\"Maximums :\", fc2_ops[2])\n",
    "print(\"Total :\", fc2_ops[3])\n",
    "print()\n",
    "\n",
    "# Print operation counts for fully connected layer 3\n",
    "print(\"Operations for fully connected layer 3:\")\n",
    "print(\"Multiplications :\", fc3_ops[0])\n",
    "print(\"Additions :\", fc3_ops[1])\n",
    "print(\"Maximums :\", fc3_ops[2])\n",
    "print(\"Total :\", fc3_ops[3])\n",
    "print()\n",
    "\n",
    "# Print operation counts for all layer\n",
    "print(\"Total operations:\", total_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (3, 32, 32))\n",
    "# Number of Parameters CONVOL1 = out_channels × (in_channels × kernel_size ** 2 + 1) = 6 * (3 * 25 + 1) = 6 * 76 = 456\n",
    "# Taille de sortie après 1 layer convolution: ((size_input - kernel_size) + 1 // stride) =  (32 - 5) + 1 = 28\n",
    "# Maxpooling (2 * 2) = Taille de sortie // 2 = 28 // 2 = 14\n",
    "# MaxPool2d 层不包含可学习的参数 = 0\n",
    "# Taille de sortie après 2 layer convolution: ((14 - 5) + 1) // 1 = 10\n",
    "# Number of Parameters CONVOL2 = out_channels × (in_channels × kernel_size ** 2 + 1) = 16 * (6 * 25 + 1) = 2416\n",
    "# Maxpooling (2 * 2) = Taille de sortie // 2 = 10 // 2 = 5\n",
    "# Number of Parameters FC1 =(in_channels + 1) × out_channels = ((16 * 5 * 5) + 1) * 120 = 48120\n",
    "# Number of Parameters FC2 =(in_channels + 1) × out_channels = ((120) + 1) * 84 = 10164\n",
    "# Number of Parameters FC3 =(in_channels + 1) × out_channels = ((84) + 1) * 10 = 850"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在运算结束时，除显示总错误率外，还显示已执行的运算次数、执行时间和每秒运算次数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Gflops/image: 0.001\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'total_ops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [14]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m     error_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m error_rate\n\u001B[0;32m---> 13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGflops/image: \u001B[39m\u001B[38;5;132;01m%.3f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[43mtotal_ops\u001B[49m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1000000000.0\u001B[39m))\n\u001B[1;32m     15\u001B[0m tt \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     16\u001B[0m error_rate_sum \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'total_ops' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# print(total_ops)\n",
    "nops = 1308168\n",
    "print(\"New Gflops/image: %.3f\"% (nops/1000000000.0))\n",
    "\n",
    "# Fonction pour calculer le taux d'erreur global\n",
    "def calculate_error_rate(predictions, labels):\n",
    "    # Implémentez votre calcul du taux d'erreur ici\n",
    "    error_rate = 0.0\n",
    "    return error_rate\n",
    "\n",
    "print(\"Gflops/image: %.3f\" % (total_ops / 1000000000.0))\n",
    "\n",
    "tt = 0\n",
    "error_rate_sum = 0.0\n",
    "total_ops_iter = 0\n",
    "\n",
    "# Epoch: 001/040 | Batch 0000/0175 | Loss: 2.3033\n",
    "# Epoch: 001/040 | Batch 0050/0175 | Loss: 2.0240\n",
    "# Epoch: 001/040 | Batch 0100/0175 | Loss: 1.9445\n",
    "# Epoch: 001/040 | Batch 0150/0175 | Loss: 1.8135\n",
    "# ***Epoch: 001/040 | Train. Acc.: 33.674% | Loss: 1.703\n",
    "# ***Epoch: 001/040 | Valid. Acc.: 34.880% | Loss: 1.670\n",
    "# Time elapsed: 1.05 min\n",
    "# Epoch: 002/040 | Batch 0000/0175 | Loss: 1.7606\n",
    "# Epoch: 002/040 | Batch 0050/0175 | Loss: 1.5473\n",
    "# Epoch: 002/040 | Batch 0100/0175 | Loss: 1.5496\n",
    "# Epoch: 002/040 | Batch 0150/0175 | Loss: 1.5093\n",
    "# ***Epoch: 002/040 | Train. Acc.: 42.819% | Loss: 1.505\n",
    "# ***Epoch: 002/040 | Valid. Acc.: 43.840% | Loss: 1.491\n",
    "# Time elapsed: 2.09 min\n",
    "\n",
    "for i in range(20): \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if torch.cuda.is_available(): torch.cuda.synchronize()\n",
    "        t0 = time.time()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if torch.cuda.is_available(): torch.cuda.synchronize()\n",
    "        dt = time.time() - t0\n",
    "        print(\"iter %2d: %.2f ms, %.4f Tflops\"% (i, dt*1000, batch_size*total_ops/dt/1000000000000))\n",
    "    \n",
    "        print(\"Epoch: %2d/%2d | Batch %2d/%2d | Loss: %.4f\"% (i, 20, batch_size*total_ops/dt/1000000000000) )\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "    # ***Epoch: 002/040 | Valid. Acc.: 43.840% | Loss: 1.491\n",
    "    print(\"***Epoch: %2d/%2d | Batch %2d/%2d | Loss: %.4f\"% (i, 20, batch_size*total_ops/dt/1000000000000) )\n",
    "    # Évaluation après chaque époque\n",
    "    print(f'Epoch {epoch + 1} Evaluation:')\n",
    "    evaluate_model(net, testloader, criterion)\n",
    "    \n",
    "average_dt = tt / 16\n",
    "average_error_rate = error_rate_sum / 20\n",
    "ops_per_second = total_ops_iter / tt\n",
    "\n",
    "print(\"Average: %.2f ms, %.4f Tflops\"% (average_dt*1000, batch_size*total_ops/average_dt/1000000000000))\n",
    "print(\"Global Error Rate: %.4f\" % average_error_rate)\n",
    "print(\"Total Operations: %d\" % total_ops_iter)\n",
    "print(\"Operations Per Second: %f\" % ops_per_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=3, stride=1),  # 修改步长为1，以便产生有效的输出\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(6, 12, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(12, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        # 在这里不需要指定固定的输出大小\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        # 修改全连接层的输入大小\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(16 * 6 * 6, 4096),  # 使用先前层的输出大小\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)  # 使用view展平张量\n",
    "        logits = self.classifier(x)\n",
    "        # 不需要在这里进行softmax操作，因为交叉熵损失函数通常会在损失计算中进行\n",
    "        return logits\n",
    "\n",
    "net = AlexNet(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=576, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 2.304\n",
      "Accuracy of the network on the 10000 test images: 10 %\n",
      "[1,  2000] loss: 2.304\n",
      "[1,  4000] loss: 2.304\n",
      "[1,  6000] loss: 2.304\n",
      "[1,  8000] loss: 2.304\n",
      "[1, 10000] loss: 2.303\n",
      "[1, 12000] loss: 2.304\n",
      "Epoch 1 Evaluation:\n",
      "Evaluation Loss: 2.304\n",
      "Accuracy of the network on the 10000 test images: 10 %\n",
      "[2,  2000] loss: 2.304\n",
      "[2,  4000] loss: 2.304\n",
      "[2,  6000] loss: 2.303\n",
      "[2,  8000] loss: 2.305\n",
      "[2, 10000] loss: 2.304\n",
      "[2, 12000] loss: 2.303\n",
      "Epoch 2 Evaluation:\n",
      "Evaluation Loss: 2.304\n",
      "Accuracy of the network on the 10000 test images: 10 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Évaluation avant la première époque\n",
    "evaluate_model(net, testloader, criterion)\n",
    "\n",
    "# Boucle pour itérer sur plusieurs époques de l'ensemble de données\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Évaluation après chaque époque\n",
    "    print(f'Epoch {epoch + 1} Evaluation:')\n",
    "    evaluate_model(net, testloader, criterion)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}