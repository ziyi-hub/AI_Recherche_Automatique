{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Initialization #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directly from data ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它将Python列表data转换为张量x_data<br/>这段代码的功能是创建了一个2x2的张量x_data，其中包含了[[1, 2], [3, 4]]这个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From a NumPy array ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码的功能是将Python列表data转换为NumPy数组np_array，然后将NumPy数组转换为PyTorch张量x_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From another tensor ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_ones = torch.ones_like(x_data)：这行代码创建了一个与x_data张量具有相同形状的张量x_ones，其中所有元素的值都设为1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_rand = torch.rand_like(x_data, dtype=torch.float)：这行代码创建了一个与x_data张量具有相同形状的张量x_rand，但其中的值是在0到1之间的随机数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.9162, 0.8121],\n",
      "        [0.5091, 0.3366]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With random or constant values ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape = (2, 3,)：这行代码定义了一个元组shape，其中包含了张量的形状信息。在这个例子中，形状为2行3列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.3554, 0.4566, 0.3081],\n",
      "        [0.5465, 0.2611, 0.8062]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Attributes #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这行代码创建了一个形状为(3, 4)的随机张量tensor。torch.rand()函数用于创建指定形状的张量，并用0到1之间的随机数填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Operations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这行代码将张量tensor移动到GPU上进行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')\n",
    "  print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard numpy-like indexing and slicing ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码使用了PyTorch库创建了一个4x4的张量（tensor），并将其所有元素初始化为1。然后，通过索引操作，将张量的第二列（索引为1的列，Python中索引从0开始）的所有元素设置为0。最后，打印输出了修改后的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码使用了PyTorch库中的torch.cat()函数，该函数用于沿指定维度拼接张量。给定的张量列表是[tensor, tensor, tensor]，即将tensor张量在水平方向（dim=1，即列的方向）上连接三次。假设初始的tensor是一个4x4的张量，那么沿着列的方向连接三次就会得到一个4x12的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=0)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplying tensors ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两种写法都会得到一个新的张量，其中每个元素是对应位置上两个原始张量对应位置上元素的乘积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.mul(tensor) \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor * tensor \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the element-wise product\n",
    "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor * tensor \\n {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码使用了PyTorch库中的矩阵乘法操作，计算了一个张量与其转置矩阵的矩阵乘积。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor.matmul(tensor.T) \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "tensor @ tensor.T \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
    "# Alternative syntax:\n",
    "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5) #函数名以_结尾的操作通常表示这是一个原地操作，也就是说，该操作会直接修改原始张量的数值而不返回新的张量。在这里，add_()函数执行了原地加法操作。\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge with NumPy #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor to NumPy array #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy array to Tensor #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# A Gentle Introduction to torch.autograd #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/lib/oar/.batch_job_bashrc: line 5: /home/ziwang/.bashrc: No such file or directory\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: torch==2.2.0 in ./.local/lib/python3.9/site-packages (from torchvision) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (8.1.2)\n",
      "Requirement already satisfied: numpy in /usr/lib/python3/dist-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (1.12)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch==2.2.0->torchvision) (2.11.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3/dist-packages (from torch==2.2.0->torchvision) (2.5)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (2.19.3)\n",
      "Requirement already satisfied: triton==2.2.0 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (4.9.0)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from torch==2.2.0->torchvision) (3.0.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.9/site-packages (from torch==2.2.0->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchvision) (12.3.101)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.local/lib/python3.9/site-packages (from sympy->torch==2.2.0->torchvision) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/ziwang/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "52.5%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# 创建了一个ResNet-18模型的实例，并指定了使用默认的预训练权重。\n",
    "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# data = torch.rand(1, 3, 64, 64): 创建了一个形状为(1, 3, 64, 64)的随机张量，表示输入数据。\n",
    "# 这个张量的形状是(batch_size, channels, height, width)，对应于一批大小为1的RGB图像，每个图像的尺寸为64x64。\n",
    "data = torch.rand(1, 3, 64, 64) \n",
    "\n",
    "# 创建了一个形状为(1, 1000)的随机张量，表示模型的输出标签。这个张量的形状是(batch_size, num_classes)，对应于模型输出的概率分布，其中包含了1000个类别的预测概率。\n",
    "labels = torch.rand(1, 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "接下来，我们将输入数据通过模型的每一层进行预测。这就是前向传递。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction = model(data) # forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "我们使用模型的预测结果和相应的标签来计算误差（损失）。下一步是通过网络反向传播误差。当我们在误差张量上调用 .backward() 时，反向传播就开始了。\n",
    "然后，Autograd 会计算每个模型参数的梯度，并存储在参数的 .grad 属性中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward() # backward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "接下来，我们加载一个优化器，在本例中，SGD 的学习率为 0.01，动量为 0.9。我们在优化器中注册模型的所有参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "最后，我们调用 .step() 启动梯度下降。优化器会根据 .grad 中存储的梯度调整每个参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim.step() #gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Neural Networks #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "Define the neural network that has some learnable parameters (or weights)\n",
    "\n",
    "Iterate over a dataset of inputs\n",
    "\n",
    "Process input through the network\n",
    "\n",
    "Compute the loss (how far is the output from being correct)\n",
    "\n",
    "Propagate gradients back into the network’s parameters\n",
    "\n",
    "Update the weights of the network, typically using a simple update rule: weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "神经网络的典型训练过程如下：\n",
    "\n",
    "定义具有某些可学习参数（或权重）的神经网络\n",
    "\n",
    "对输入数据集进行迭代\n",
    "\n",
    "通过网络处理输入\n",
    "\n",
    "计算损失（输出离正确还有多远）\n",
    "\n",
    "将梯度传回网络参数中\n",
    "\n",
    "更新网络权重，通常使用简单的更新规则：权重 = 权重 - 学习率 * 梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Define the network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义了一个名为Net的类，它是nn.Module类的子类，表示这是一个神经网络模型。\n",
    "class Net(nn.Module):\n",
    "\n",
    "    # 这是Net类的构造函数，用于初始化模型的各个层。\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # 第一个参数是输入通道数，第二个参数是输出通道数，第三个参数是卷积核的大小。\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        # 这三行代码定义了三个全连接层。nn.Linear表示线性变换，第一个参数是输入特征数，第二个参数是输出特征数。\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    # 前向传播函数\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window 这两行代码进行了卷积层后的最大池化操作，用于提取特征并降低维度。\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension 将输入张量展平，保留批次维度。\n",
    "        \n",
    "        #这三行代码应用了ReLU激活函数和线性变换来处理全连接层的输出\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1的权重是一个四维张量，形状为[6, 1, 5, 5]。这表示有6个输出通道、1个输入通道，每个通道使用大小为5x5的卷积核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0083, -0.0866,  0.0888, -0.0644, -0.0777,  0.0448,  0.0930,  0.0096,\n",
      "         -0.0385, -0.0977]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32) #这表示一个包含一个样本的批次，每个样本有一个通道，并且是 32x32 的图像\n",
    "out = net(input)\n",
    "print(out) #输出结果 out，它是一个大小为 (1, 10) 的张量。每个元素表示对应类别的预测分数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.zero_grad() #zero_grad() 来清除之前的梯度，以避免梯度的累积影响下一次的计算。\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "torch.nn 仅支持迷你批次。整个 torch.nn 软件包只支持迷你样本批次的输入，而不支持单个样本的输入。\n",
    "\n",
    "例如，nn.Conv2d 将接收 nSamples x nChannels x Height x Width 的 4D 张量。\n",
    "\n",
    "如果只有单个样本，只需使用 input.unsqueeze(0) 添加一个假的批次维度即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Loss Function ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "损失函数接收（输出、目标）这对输入，并计算出一个值来估计输出与目标之间的距离。\n",
    "\n",
    "nn 软件包中有几种不同的损失函数。一个简单的损失函数是：nn.MSELoss，它计算输出与目标之间的均方误差。\n",
    "\n",
    "例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5286, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss() # 表示均方误差损\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x7f5ca81951c0>\n",
      "<AddmmBackward0 object at 0x7f5ca8195fa0>\n",
      "<AccumulateGrad object at 0x7f5ca81951c0>\n"
     ]
    }
   ],
   "source": [
    "# MSELoss 这行代码打印了损失函数的反向传播函数，即均方误差损失函数 MSELoss。\n",
    "print(loss.grad_fn)  \n",
    "\n",
    "# 这行代码通过 next_functions 访问了损失函数计算过程中的下一级函数。由于均方误差损失函数是通过 output 和 target 计算得到的，\n",
    "# 因此 next_functions 中的第一个元素对应于 output，即模型的输出。因为我们的模型最后一层是全连接层 Linear，所以这里打印出来的是 Linear 函数。\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear \n",
    "\n",
    "# 这行代码进一步访问了损失函数计算过程中下一级的函数。在这里，我们进入了全连接层 Linear 的计算过程。\n",
    "# 在全连接层中，输入经过线性变换后会被传递给激活函数，而在我们的模型中，激活函数是 ReLU。所以这里打印出来的是 ReLU 函数。\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## BackProp ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "要反向传播错误，我们只需 loss.backward()。不过您需要清除现有的梯度，否则梯度将累积到现有梯度中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0188,  0.0033,  0.0204,  0.0176, -0.0043,  0.0171])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Update the weights ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "实际应用中最简单的更新规则是随机梯度下降法（SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 梯度下降的迭代过程，从而使模型的参数朝着损失函数减小的方向更新。\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "不过，由于使用的是神经网络，因此需要使用各种不同的更新规则，如 SGD、Nesterov-SGD、Adam、RMSProp 等。为此，我们开发了一个小软件包：torch.optim，用于实现所有这些方法。使用它非常简单："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Training a Classifier #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Training an image classifier ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "我们将依次执行以下步骤:\n",
    "\n",
    "- 使用 torchvision 加载 CIFAR10 训练数据集和测试数据集并将其标准化\n",
    "- 定义卷积神经网络\n",
    "- 定义损失函数\n",
    "- 在训练数据上训练网络\n",
    "- 在测试数据上测试网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 1. Load and normalize CIFAR10 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "torchvision 数据集的输出是范围为 [0, 1] 的 PILImage 图像。我们将其转换为归一化范围为 [-1, 1] 的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57.9%IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose( # 创建了一个转换组合，将一系列的数据预处理操作组合在一起。这里使用了两个预处理操作\n",
    "    [transforms.ToTensor(), # 将图像转换为 PyTorch 张量，并将像素值缩放到 [0, 1] 的范围\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 对图像进行标准化处理，减去均值（0.5）并除以标准差（0.5）\n",
    "\n",
    "batch_size = 4 #指定了数据加载器每次加载的批次大小，这里设置为 4。\n",
    "\n",
    "# 创建了 CIFAR-10 数据集的训练集对象。root 参数指定了数据集存储的根目录，train=True 表示加载训练集，\n",
    "# download=True 表示如果数据集不存在则自动下载，transform=transform 表示应用之前定义的数据预处理操作。\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "# 创建了一个训练集数据加载器。trainloader 负责从训练集中加载数据，shuffle=True 表示每个 epoch 都会对数据进行洗牌，\n",
    "# num_workers=2 表示使用两个子进程来加载数据以加快速度。\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# 这里分别创建了 CIFAR-10 数据集的测试集对象和测试集数据加载器。\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird  cat   ship  car  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "# 在显示之前，需要进行反标准化操作，即将图像的像素值从 [-1, 1] 的范围还原到 [0, 1] 的范围，\n",
    "# 然后将张量转换为 NumPy 数组，并进行维度转置\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader) #创建了一个迭代器 dataiter，用于从训练集数据加载器中迭代获取数据。\n",
    "images, labels = next(dataiter) #从迭代器中获取了一批数据，其中 images 是图像数据，labels 是对应的标签。\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images)) #用于将一批图像组合成一个网格，方便显示\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 2. Define a Convolutional Neural Network ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 3.Define a Loss function and optimizer ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#这行代码定义了损失函数，即交叉熵损失函数。交叉熵损失函数通常用于多类别分类问题\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#这行代码定义了优化器，即随机梯度下降（SGD）优化器。SGD是一种常用的优化算法，用于更新神经网络的权重以最小化损失函数。\n",
    "#lr=0.001指定了学习率，即每次更新时的步长。momentum=0.9是SGD的一个超参数，用于加速SGD在相关方向上前进，并减小波动。\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 4.Train the network ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.168\n",
      "[1,  4000] loss: 1.840\n",
      "[1,  6000] loss: 1.660\n",
      "[1,  8000] loss: 1.580\n",
      "[1, 10000] loss: 1.525\n",
      "[1, 12000] loss: 1.468\n",
      "[2,  2000] loss: 1.417\n",
      "[2,  4000] loss: 1.376\n",
      "[2,  6000] loss: 1.363\n",
      "[2,  8000] loss: 1.345\n",
      "[2, 10000] loss: 1.304\n"
     ]
    }
   ],
   "source": [
    "# for epoch in range(2):：这是一个外部循环，用于迭代整个数据集多次，每次称为一个\"epoch\"。\n",
    "# 在这个示例中，数据集将被遍历两次。\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    # 初始化一个变量running_loss，用于跟踪每个epoch中的累积损失。\n",
    "    running_loss = 0.0\n",
    "\n",
    "    #这是一个内部循环，用于遍历训练数据加载器trainloader中的每个批次\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # 解压批次数据，将输入和对应的标签分别赋给inputs和labels变量。\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        # 将输入数据inputs通过神经网络net进行前向传播，得到输出。\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #损失函数criterion计算模型预测值outputs与真实标签labels之间的损失。\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #调用backward()方法进行反向传播，计算损失对模型参数的梯度。\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        #累积当前批次的损失到running_loss变量中。\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        #每遍历2000个批次（mini-batches），打印一次损失。这个条件用于控制打印频率。\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "\n",
    "            #打印当前epoch和批次数，以及当前2000个mini-batches的平均损失。\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "\n",
    "            #重置running_loss，以便计算下一个2000个mini-batches的损失。\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 5. Test the network on the test data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#test-the-network-on-the-test-data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}